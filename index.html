<!doctype html>
<html lang="en">

<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-21408087-2"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'UA-21408087-2');
    </script>

    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>Grace Hešeri's Website</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="manifest" href="site.webmanifest">
    <link rel="apple-touch-icon" href="icon.png">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="css/style_v2.css">
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
</head>

<body>
    <div class="wrapper">
        <nav id="sidebar">
            <div id="sidebar-wrapper">
                <div class="sidebar-header">
                    <h1><span class="first-name">Grace</span> <span class="last-name">Gao</span></h1>
                    <p>Personal Website</p>
                </div>

                <ul class="list-unstyled components">
                     <li class="active" > <a href="index.html">About</a> </li> 
                </ul>
                <ul id="links" class="list-unstyled">
                    <li><a class="mail">
                            <svg style="width:20px;height:20px" class="mr-1" viewBox="0 0 24 24">
                                <path fill="currentColor" d="M20,8L12,13L4,8V6L12,11L20,6M20,4H4C2.89,4 2,4.89 2,6V18A2,2 0 0,0 4,20H20A2,2 0 0,0 22,18V6C22,4.89 21.1,4 20,4Z" />
                            </svg>
                            grace.heseri at gmail.com
                        </a>
                    </li>
                    <li><a href="https://scholar.google.com/citations?user=nYYIYaUAAAAJ">
                            <svg style="width:20px;height:20px" class="mr-1" viewBox="0 0 24 24">
                                <path fill="currentColor" d="M12,3L1,9L12,15L21,10.09V17H23V9M5,13.18V17.18L12,21L19,17.18V13.18L12,17L5,13.18Z" />
                            </svg>
                            Google Scholar
                        </a>
                    </li>
                    <li> <a href="https://github.com/GGGHSL">
                            <svg style="width:20px;height:20px" class="mr-1" viewBox="0 0 24 24">
                                <path fill="currentColor" d="M12,2A10,10 0 0,0 2,12C2,16.42 4.87,20.17 8.84,21.5C9.34,21.58 9.5,21.27 9.5,21C9.5,20.77 9.5,20.14 9.5,19.31C6.73,19.91 6.14,17.97 6.14,17.97C5.68,16.81 5.03,16.5 5.03,16.5C4.12,15.88 5.1,15.9 5.1,15.9C6.1,15.97 6.63,16.93 6.63,16.93C7.5,18.45 8.97,18 9.54,17.76C9.63,17.11 9.89,16.67 10.17,16.42C7.95,16.17 5.62,15.31 5.62,11.5C5.62,10.39 6,9.5 6.65,8.79C6.55,8.54 6.2,7.5 6.75,6.15C6.75,6.15 7.59,5.88 9.5,7.17C10.29,6.95 11.15,6.84 12,6.84C12.85,6.84 13.71,6.95 14.5,7.17C16.41,5.88 17.25,6.15 17.25,6.15C17.8,7.5 17.45,8.54 17.35,8.79C18,9.5 18.38,10.39 18.38,11.5C18.38,15.32 16.04,16.16 13.81,16.41C14.17,16.72 14.5,17.33 14.5,18.26C14.5,19.6 14.5,20.68 14.5,21C14.5,21.27 14.66,21.59 15.17,21.5C19.14,20.16 22,16.42 22,12A10,10 0 0,0 12,2Z" />
                            </svg>
                            GGGHSL</a>
                    </li>
                    <!-- <li> <a href="https://linkedin.com/in/sx-yu"> -->
                    <!--         <svg style="width:20px;height:20px" viewBox="0 0 24 24"> -->
                    <!--             <path fill="currentColor" d="M19 3A2 2 0 0 1 21 5V19A2 2 0 0 1 19 21H5A2 2 0 0 1 3 19V5A2 2 0 0 1 5 3H19M18.5 18.5V13.2A3.26 3.26 0 0 0 15.24 9.94C14.39 9.94 13.4 10.46 12.92 11.24V10.13H10.13V18.5H12.92V13.57C12.92 12.8 13.54 12.17 14.31 12.17A1.4 1.4 0 0 1 15.71 13.57V18.5H18.5M6.88 8.56A1.68 1.68 0 0 0 8.56 6.88C8.56 5.95 7.81 5.19 6.88 5.19A1.69 1.69 0 0 0 5.19 6.88C5.19 7.81 5.95 8.56 6.88 8.56M8.27 18.5V10.13H5.5V18.5H8.27Z" /> -->
                    <!--         </svg> -->
                    <!--         sx-yu -->
                    <!--     </a> -->
                </ul>
            </div>
        </nav>

        <div id="content">
            
    <div class="about">
        <img class="banner-image" src="img/banner-new.jpg" title="Universal Studio Beijing">

        <p>
            Hi! My name is Grace (a.k.a Gege). I am currently a research staff at National Laboratory of Pattern Recognition (NLPR) in the Institute of Automation, Chinese Academy of Sciences (CASIA), Beijing, China, working with <a href='https://rhe-web.github.io/'>Prof. Dr. Ran He</a>.
            I'll be a Ph.D. student in the <a href="http://www.cvlibs.net/">Autonomous Vision Group</a> (AVG) starting Spring 2022, advised by <a href="https://ps.is.mpg.de/~ageiger">Prof. Dr. Andreas Geiger</a>.
        </p>
        <p>
            My research interest is at the intersection of vision and learning. Currently, my research focuses on controllable image synthesis, as it provides a way to bridge the human will with artificial machines. I'm also working on causal representation learning to achieve better control and generalization ability in generative modeling.
        </p>
        <p>
            Prior to NLPR, I studied in two Chinese "Excellent" departments of statistics in Beijing, i.e., School of Statistics, Renmin University of China (M.Sc. 2020) and School of Mathematics and Statistics, Central University of Finance and Economics (B.Sc. 2017), where I majored in Applied Statistics.
        </p>
    </div>
    <div class="timeline pt-2">
        
        <div class="timeline-entry">
            <div class="timeline-image-holder">
            
            <img src="img/timeline/avg.png" alt="Autonomous Vision Group (AVG)">
            
            </div>
            <div class="timeline-time">Spring 2022</div>
            <div class="timeline-org">Autonomous Vision Group (AVG)</div>
            <div class="timeline-position">Ph.D. Student</div>
            <div class="timeline-description">3D-Aware Visual Representations</div>
        </div>
        
        <div class="timeline-entry">
            <div class="timeline-image-holder">
            
            <img src="img/timeline/nlpr.png" alt="NLPR, CASIA">
            
            </div>
            <div class="timeline-time">Summer 2020-Spring 2022</div>
            <div class="timeline-org">NLPR, CASIA</div>
            <div class="timeline-position">Research Staff</div>
            <div class="timeline-description">Group Leader: <a href='https://rhe-web.github.io/'>Prof. Dr. Ran He</a>; worked on controllable image synthesis</div>
        </div>
        
        <div class="timeline-entry">
            <div class="timeline-image-holder">
            
            <img src="img/timeline/pku.png" alt="Peking University">
            
            </div>
            <div class="timeline-time">Fall 2019-Spring 2020</div>
            <div class="timeline-org">Peking University</div>
            <div class="timeline-position">Research Intern</div>
            <div class="timeline-description">Host: <a href='https://www.icst.pku.edu.cn/xztd/1298696.htm/'>Prof. Dr. Yongtao Wang</a>; worked on learning semantic representations from comic/manga and cross-domain image synthesis</div>
        </div>
        
        <div class="timeline-entry">
            <div class="timeline-image-holder">
            
            <img src="img/timeline/sense.png" alt="SenseTime">
            
            </div>
            <div class="timeline-time">Summer 2019</div>
            <div class="timeline-org">SenseTime</div>
            <div class="timeline-position">Research Intern</div>
            <div class="timeline-description">Worked on statistical inference from structured medical/underwriting data</div>
        </div>
        
        <div class="timeline-entry">
            <div class="timeline-image-holder">
            
            <img src="img/timeline/iqubic.png" alt="Intelligence Qubic">
            
            </div>
            <div class="timeline-time">Summer 2018</div>
            <div class="timeline-org">Intelligence Qubic</div>
            <div class="timeline-position">Research Intern</div>
            <div class="timeline-description">Responsible for applying evolutionary algorithms on differentiable NAS to improve the performance of AutoML models</div>
        </div>
        
        <div class="timeline-entry">
            <div class="timeline-image-holder">
            
            <img src="img/timeline/galaxy.png" alt="China Galaxy Securities">
            
            </div>
            <div class="timeline-time">Fall 2017</div>
            <div class="timeline-org">China Galaxy Securities</div>
            <div class="timeline-position">Data Analysis Intern</div>
            <div class="timeline-description">Worked on data mining for statistical modeling in the Internet Finance Department</div>
        </div>
        
    </div>
    <div class="pt-4">
        <h2>Publications</h2>
        <div id="pubs">
            
            <div class="pub row pt-3 pb-3">
                <div class="col-sm-2 pub-preview">
                    
                    <img src="img/cartrans.jpg" alt="Causal Representation Learning for Context-Aware Face Transfer">
                    
                </div>
                <div class="col">
                    <h4>Causal Representation Learning for Context-Aware Face Transfer</h4>
                    <div class="pub-authors">
                        
                        Gege Gao, 
                        
                        Huaibo Huang, 
                        
                        Chaoyou Fu, 
                        
                        Ran He
                        
                    </div>
                    <div class="pub-venue pb-1">
                        <small>
                        Preprint
                        <span class="pub-award">  </span>
                        </small>
                    </div>
                    <div class="pub-links">
                    
                    <a href="https://arxiv.org/abs/2110.01571">arXiv</a>
                    
                    
                    
                    
                    
                    </div>
                    <div class="pub-description pt-1">
                        
                        <p class="pub-abstract">
                        Human face synthesis involves transferring knowledge about the identity and identity-dependent shape of a human face to target face images where the context (\eg, facial expressions, head poses, and other background factors) may change dramatically. Human faces are non-rigid, so facial expression leads to deformation of face shape, and head pose also affects the face observed in 2D images. A key challenge in face transfer is to match the face with unobserved new contexts, adapting the identity-dependent face shape (IDFS) to different poses and expressions accordingly. In this work, we find a way to provide prior knowledge for generative models to reason about the appropriate appearance of a human face in response to various expressions and poses. We propose a novel context-aware face transfer model, called CarTrans, that incorporates causal effects of contextual factors into face representation, and thus is able to be aware of the uncertainty of new contexts. We estimate the effect of facial expression and head pose in terms of counterfactuals by designing a controlled intervention trial, thus avoiding the need for dense multi-view observations to cover the pose-expression space well. Moreover, we propose a kernel regression-based encoder that eliminates the identity specificity of the target face when encoding contextual information from the target image. The resulting method shows impressive performance, allowing fine-grained control over face shape and appearance under various contextual conditions.
                        </p>
                        
                    </div>
                </div>
            </div>
            
            <div class="pub row pt-3 pb-3">
                <div class="col-sm-2 pub-preview">
                    
                    <img src="img/infoswap.png" alt="Information Bottleneck Disentanglement for Identity Swapping">
                    
                </div>
                <div class="col">
                    <h4>Information Bottleneck Disentanglement for Identity Swapping</h4>
                    <div class="pub-authors">
                        
                        Gege Gao, 
                        
                        Huaibo Huang, 
                        
                        Chaoyou Fu, 
                        
                        Zhaoyang Li, 
                        
                        Ran He
                        
                    </div>
                    <div class="pub-venue pb-1">
                        <small>
                        CVPR 2021
                        <span class="pub-award">  </span>
                        </small>
                    </div>
                    <div class="pub-links">
                    
                    
                    <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Information_Bottleneck_Disentanglement_for_Identity_Swapping_CVPR_2021_paper.html">Paper</a>
                    
                    
                    
                    <a href="https://github.com/GGGHSL/InfoSwap-master">Code</a>
                    
                    
                    </div>
                    <div class="pub-description pt-1">
                        
                        <p class="pub-abstract">
                        Improving the performance of face forgery detectors often requires more identity-swapped images of higher-quality. One core objective of identity swapping is to generate identity-discriminative faces that are distinct from the target while identical to the source. To this end, properly disentangling identity and identity-irrelevant information is critical and remains a challenging endeavor. In this work, we propose a novel information disentangling and swapping network, called InfoSwap, to extract the most expressive information for identity representation from a pre-trained face recognition model. The key insight of our method is to formulate the learning of disentangled representations as optimizing an information bottleneck trade-off, in terms of finding an optimal compression of the pre-trained latent features. Moreover, a novel identity contrastive loss is proposed for further disentanglement by requiring a proper distance between the generated identity and the target. While the most prior works have focused on using various loss functions to implicitly guide the learning of representations, we demonstrate that our model can provide explicit supervision for learning disentangled representations, achieving impressive performance in generating more identity-discriminative swapped faces.
                        </p>
                        
                    </div>
                </div>
            </div>
            
            <small>
            * = Equal contribution
            </small>
        </div>
    </div>
    <div class="coursework pt-4">
        <h2>Education</h2>
        <div id="coursework-collapse">
            <h4>M.Sc. in Applied Statistics, 2020</h4>
<ul>
    <li>School of Statistics</li>
    <li>Renmin University of China</li>
</ul>
<h4>B.Sc. in Applied Statistics, 2017</h4>
<ul>
    <li>School of Mathematics and Statistics</li>
    <li>Central University of Finance and Economics</li>
</ul>
        </div>
    </div>
    <div class="coursework pt-2">
        <h2>Misc</h2>
        <p>
            I was born in Beijing, China. My Chinese name is Gege Gao (高格格). Hešeri (赫舍里) is my ancestral surname.
        </p>
    </div>
    <div class="pt-2">
        <small>
            The source code for this website is forked from <a href="https://github.com/sxyu/sxyu.github.io">this repo</a>.
        </small>
    </div>

        </div>
    </div>
</body>


<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

</html>